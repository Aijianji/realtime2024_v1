#### 第七天

提问

```
pipline 数据管道

线上
阿里云的dataworks、dataV
dataworks:是由阿里云提供的一款云原生数据智能开发平台。数据集成、数据开发、数据管理、数据治理、调度与运维
dataV(数据可视化)

线下
CDH、CDP、TDH
CDH:将 Hadoop 生态系统中的多个组件（如 HDFS、YARN、Hive、HBase 等）进行整合、测试和打包，使这些组件能够协同工作。
特点:稳定性高、管理方便、生态丰富
CDP:在 CDH 的基础上进行了升级和扩展，不仅涵盖了传统的大数据处理功能，还整合了机器学习、实时数据处理等更多先进的技术，提供了一个更加全面的数据管理和分析解决方案。
特点:融合多种技术、多模式数据处理、云原生支持
TDH:一站式大数据平台。它集成了多个自主研发的大数据组件，涵盖了数据存储、计算、分析和管理等多个环节，提供了完整的大数据解决方案
特点:高性能计算引擎、安全可控、国产自主可控优势

Java 的数据类型分为基本数据类型(8种)和引用数据类型(类、接口、枚举、集合数组等)

位置下推
在大数据处理领域，位置下推是一种优化技术。它主要是将数据过滤（筛选）条件尽可能地推到数据存储层或者靠近数据源的位置进行处理。例如，在从分布式存储系统（如 HDFS）读取数据用于分析时，不是先将所有数据读取到计算引擎（如 Spark、Flink 等）中再进行过滤，而是在存储系统读取数据的过程中，就根据过滤条件丢弃那些不符合要求的数据，从而减少数据传输量和后续计算引擎的处理负担。
```

自我介绍

```
  面试官你好，我叫石轶群。从事大数据开发行业已经五年了。平时使用的，线上的话:阿里云的dataworks、dataV等。线下集群的话:CDH、CDP、TDH用的比较多。可以完成搭建，测试，部署，上线等功能。工作内容以离线任务较多，包括数仓的搭建，sql的使用等，实时的也会和同事们一起做一点儿。会使用java语言用于开发,scala语言，python语言爬虫等。以上就是我的自我介绍，谢谢面试官。
```

晚任务

```
将jar部署至yarn上(flink on yarn)
1.standalone模式
2.session模式 提前预定好大小，但是不知道数据来的时候多大
3.per-job 走网络传输 flink 1.15.1版本前用
4.application 现在用的，将东西存入hdfs，公平
之前一直用的session模式
现在用第四个
不开flink(只是用了提交)、别忘了开zookeeper
./bin/flink run-application -t yarn-application -c  类地址 jar包在虚拟机的地址

补充
1.关闭nc -lk 9999后再创建nc -lk 9999如果说被占用
netstat -tlnp | grep 9999杀死那个进程就可以重新创建了
2.export HADOOP_CLASSPATH=$(hadoop classpath) 这条命令主要用于设置HADOOP_CLASSPATH环境变量,它告诉 Java 虚拟机（JVM）到哪里去寻找用户自定义的类和相关的依赖库。部署的时候报错可以试一下，但并不清楚到底是不是这个的原因。
```

